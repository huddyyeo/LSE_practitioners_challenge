# -*- coding: utf-8 -*-
"""corrfx.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wOrUZeFF6QaTrSYxi4h5ZfmQS0GPg1JW
"""

#lib of functions to be imported
import numpy as np
from scipy.stats import pearsonr
from scipy.stats import skew
from scipy.stats import kurtosis
import pandas as pd

'''
This function takes two time series and applies a rolling window, calculating the correlation for each window. 
It returns a vector of correlation values
'''

def roll_corr(x,y,length=5):
  corr=[]
  x_len=len(x)
  if (x_len!=len(y)):
    print("length of dataset do not match")
    return
  if (length>x_len):
    print("length of rolling window exceeds data")
    return
  for i in range(x_len):
    if (i+length>=x_len):
      break
    temp=pearsonr(x[i:i+length],y[i:i+length])[0]
    corr.append(temp)
  return corr

'''
Class for creating a data environment. Input a vector of urls and the data is imported, cleaned and stored in the class.
'''
class data_environment(object):
  def __init__(self,url_list):
    self.init_data(url_list) 
    self.preprocess_data()

  def init_data(self,url_list): #initialise data
    self.raw_data=[]
    for url in url_list:
      self.raw_data.append(pd.read_csv(url))  

  def get_daily_price(self,data): #gets average of High and Low
    return data.loc[:,['High','Low']].mean(axis=1).values

  def get_logr(self,data): #calculates 1 day log returns
    returns=data[1:]/data[:-1]
    return pd.Series(np.log(returns)).rename('Log-return')

  def get_datetime(self,data): #returns Date column as a datetime column
    date=pd.to_datetime(data.Date)
    return date     

  def preprocess_data(self): #run all preprocessing and cleaning
    self.data=[]
    for i in range(len(self.raw_data)):
      date=self.get_datetime(self.raw_data[i])
      logr=self.get_logr(self.get_daily_price(self.raw_data[i]))
      self.data.append(pd.concat([date,logr],axis=1))

'''
Function that takes in data environment and merges 2 time series, can be potentially extended
'''

def merge(data_env,i=0,j=1):
  df=pd.merge(data_env.data[i],data_env.data[j],on='Date',how='inner')
  df=df.dropna()
  return df

'''
Run rolling correlation windows, from length 4 to 200(1 year)
From the correlation data calculated, obtain first 4 central moments 
'''

def test_lengths(df):
  corr_data=pd.DataFrame(columns=['window_length','mean','var','skew','kurtosis'])
  for i in range(4,201):
    values=roll_corr(df.loc[:,'Log-return_x'].values,df.loc[:,'Log-return_y'].values,i)
    entry_dict={'window_length':i,
                'mean':np.mean(values),
                'var':np.var(values),
                'skew':skew(values),
                'kurtosis':kurtosis(values)}
    corr_data=corr_data.append(entry_dict,ignore_index=True)
  return corr_data